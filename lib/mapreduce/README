
--------------------------------------------
Map-Reduce Library
--------------------------------------------
{DOCPATH}

1.Data flow description for applications based on MapReduce library:
Every Map node has single input file, every Reduce node has single
output file; Input file with data for every Map node reading by blocks
of configured size and default chunk size is 1MB. Block size can be
overrided by environment variable MAP_CHUNK_SIZE. Readed chunk of data
is passed into user defined Map function, that parses it and create
HASHes for input keys and return key and value buffers. Size of key
and value can be vary and also can contain binary data;
At the next stage - map node is sorts data by key and applying user
defined Combine function for sorted data to reduce it. This step will
skipped if Combine function not defined.
At the next stage MapReduce library for every map node creating
histogram and sending each to other map nodes to calculate resulted
histogram on every map node at once; Based on resulted histograms -
keys data are distributing to reducers; Reducers are receiving sorted
data from map nodes while they are 'leave' and then doing merge for
every portion of received data by applying Combine function if it's
defined. Map node is staying to be 'leave' and listening by Reducer
node while not received MAP_EXCLUDE packet data. In case if Reducer
node recevied MAP_EXCLUDE packet it exclude that map node from nodes
list to read, and in case if all map nodes that should be listen by
reducer are not 'leave' e.g. excluded then it breaks waiting loop at
all and calling Reduce() function to finalize result and finish single
reducer node; Only when every reduce node called Reduce() function
then mapreduce task is done.
2.Object files belongs to this library are resides in libmapreduce.a
and also MapReduce uses Networking Library to get cluster distributed
configuration; In order to link it use folowing:
LDFLAGS=-lmapreduce -lnetworking
3. Examples of usage: samples/wordcount
